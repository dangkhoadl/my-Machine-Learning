{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Machine translation seq2seq + Attention model German -> English\n",
    "#### References\n",
    "- [Paper](https://arxiv.org/abs/1409.0473)\n",
    "- [Github](https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb)\n",
    "- [Youtube](https://www.youtube.com/watch?v=sQUqQddQtB4&feature=youtu.be)\n",
    "\n",
    "\n",
    "#### Ideas\n",
    "- Original Seq2Seq: context vector maybe bottleneck, cant convey enough energy if the sentence is too long\n",
    "\n",
    "<img src=\"./assets/4.png\" width=\"500\"/>\n",
    "\n",
    "- Improved: Send the context vector to every cell of the decoder\n",
    "\n",
    "<img src=\"./assets/5.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Use {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'morning']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_en(\"good morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['morgen', 'guten']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_de(\"guten morgen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get dataset from torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangkhoadl/anaconda3/envs/py37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "german = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "english = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangkhoadl/anaconda3/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'), \n",
    "    fields = (german, english))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei']\n",
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "# DE (reverse)\n",
    "print(vars(train_data.examples[0])['src'])\n",
    "\n",
    "# En\n",
    "print(vars(train_data.examples[0])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'männer', 'mehrere']\n",
      "['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']\n"
     ]
    }
   ],
   "source": [
    "# DE (reverse)\n",
    "print(vars(train_data.examples[1])['src'])\n",
    "\n",
    "# En\n",
    "print(vars(train_data.examples[1])['trg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, min_freq = 2)\n",
    "english.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7854\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(german.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Preview dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangkhoadl/anaconda3/envs/py37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader size: 907\n",
      "Valid dataloader size: 32\n",
      "Test dataloader size: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataloader size:\", len(train_iterator))\n",
    "print(\"Valid dataloader size:\", len(valid_iterator))\n",
    "print(\"Test dataloader size:\", len(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangkhoadl/anaconda3/envs/py37/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source[0] tensor size: torch.Size([26, 32])\n",
      "Target[0] tensor size: torch.Size([23, 32])\n",
      "\n",
      "Source[1] tensor size: torch.Size([27, 32])\n",
      "Target[1] tensor size: torch.Size([25, 32])\n",
      "\n",
      "Source[2] tensor size: torch.Size([27, 32])\n",
      "Target[2] tensor size: torch.Size([33, 32])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_iterator):\n",
    "    X = data.src\n",
    "    y = data.trg\n",
    "\n",
    "    # (Input_dim, batch_size)\n",
    "    print(f\"Source[{i}] tensor size: {X.size()}\")\n",
    "\n",
    "    # (Output_dim, batch_size)\n",
    "    print(f\"Target[{i}] tensor size: {y.size()}\",end=\"\\n\\n\")\n",
    "\n",
    "    if i == 2: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Encoder\n",
    "<img src=\"./assets/6.png\" width=\"750\"/>\n",
    "\n",
    "#### Architecture\n",
    "- 1 Embedded layer\n",
    "- 1 biLSTM layer:\n",
    "    + foward: $x_0^\\rightarrow = \\text{<sos>}, x_1^\\rightarrow = \\text{guten}, x_2^\\rightarrow = \\text{morgen}, x_3^\\rightarrow = \\text{<eos>}$\n",
    "    + backward: $x_0^\\leftarrow = \\text{<eos>}, x_1^\\leftarrow = \\text{morgen}, x_2^\\rightarrow = \\text{guten}, x_3^\\rightarrow = \\text{<sos>}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangkhoadl/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from Models.Seq2Seq_Attention import Encoder\n",
    "\n",
    "\n",
    "ENC_EMB_DIM = 300\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(\n",
    "    source_vocab_size=len(german.vocab),\n",
    "    embedding_size=ENC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=ENC_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(33, 64).long().cuda()\n",
    "\n",
    "encoder_states, hidden_fc, cell_fc = enc(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decoder\n",
    "\n",
    "#### Architecture\n",
    "- 1 Embedded layer\n",
    "- attention - context_vector\n",
    "- 1 LSTM layer\n",
    "- 1 fully connected\n",
    "\n",
    "#### Context vector implementation\n",
    "\n",
    "<img src=\"./assets/1.jpg\" width=\"250\"/>\n",
    "\n",
    "- context vector:\n",
    "    $$c_i = \\sum\\limits_{j=1}^{Tx} \\alpha_{ij}h_j$$\n",
    "\n",
    "- Where\n",
    "    + $h_j$: encoder states\n",
    "    + $\\alpha_{ij}$ is the weight: $\\alpha_{ij} = \\frac{exp(e_{ij})}{\\sum\\limits_{k=1}^{Tx}exp(e_{ik})} = softmax(e_{ij})$ \n",
    "        + $e_{ij}$ is energy defined by: $e_{ij} = a(s_{i-1}, h_j)$\n",
    "            + $s_{i-1}$: encoder hidden\n",
    "            + $h_j$: encoder states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Seq2Seq_Attention import Decoder\n",
    "\n",
    "DEC_EMB_DIM = 300\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "dec = Decoder(\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    embedding_size=DEC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=DEC_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = torch.rand(33, 64).long().to(device)\n",
    "\n",
    "predictions_squ, hidden, cell = dec(XX[0], encoder_states, hidden_fc, cell_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Seq2Seq_Attention import Seq2Seq\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder=enc,\n",
    "    decoder=dec,\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC_EMB_DIM = 300\n",
    "ENC_DROPOUT = 0.0\n",
    "\n",
    "DEC_EMB_DIM = 300\n",
    "DEC_DROPOUT = 0.0\n",
    "\n",
    "HID_DIM = 1024\n",
    "N_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    source_vocab_size=len(german.vocab),\n",
    "    embedding_size=ENC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=ENC_DROPOUT).to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    embedding_size=DEC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=DEC_DROPOUT).to(device)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder=encoder_net,\n",
    "    decoder=decoder_net,\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss_fn\n",
    "import torch.nn as nn\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"exp/Seq2Seq_Attention/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "\n",
    "load_model = False\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"exp/Seq2Seq_Attention/trained_model.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = False\n",
    "LOG_FILE = \"exp/Seq2Seq_Attention/train.log\"\n",
    "\n",
    "if train_mode == True:\n",
    "    # a boat with several men on it is being pulled ashore by a large team of horses.\n",
    "    sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_iterator):\n",
    "            # Get input and targets and get to cuda\n",
    "            source = batch.src.to(device)\n",
    "            target = batch.trg.to(device)\n",
    "\n",
    "            # Forward prop\n",
    "            output = model(source, target)\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "            # within a healthy range\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        save_checkpoint(checkpoint, \"exp/Seq2Seq_Attention/trained_model.pth.tar\")\n",
    "\n",
    "\n",
    "        # Plot to tensorboard every epoch\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        translated_sentence = translate_sentence(\n",
    "            model, sentence, german, english, device, max_length=50\n",
    "        )\n",
    "        with open(LOG_FILE, \"a+\") as file:\n",
    "            file.write(f\"[Epoch {epoch} / {num_epochs}]: loss: {loss.item()}\\n\")\n",
    "            file.write(f\"Translated example sentence: {' '.join(translated_sentence)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load(\"exp/Seq2Seq_Attention/trained_model.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence: . freien im tag schönen einen genießen sohn kleiner ihr und mutter eine\n",
      "groundtruth: a mother and her young song enjoying a beautiful day outside .\n",
      "translated: a mother and her daughter enjoying their small day outside .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = test_data[10].src\n",
    "groundtruth = test_data[10].trg\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, german, english, device, max_length=50\n",
    ")\n",
    "\n",
    "print(f'''\n",
    "sentence: {' '.join(sentence)}\n",
    "groundtruth: {' '.join(groundtruth)}\n",
    "translated: {' '.join(translated_sentence[:-1])}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence: . feld dem auf trompete spiel einem bei spielt teenagerin eine\n",
      "groundtruth: a teenager plays her trumpet on the field at a game .\n",
      "translated: a toddler player is playing a game in the field during a game .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = test_data[21].src\n",
    "groundtruth = test_data[21].trg\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, german, english, device, max_length=50\n",
    ")\n",
    "\n",
    "print(f'''\n",
    "sentence: {' '.join(sentence)}\n",
    "groundtruth: {' '.join(groundtruth)}\n",
    "translated: {' '.join(translated_sentence[:-1])}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 21.46\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
