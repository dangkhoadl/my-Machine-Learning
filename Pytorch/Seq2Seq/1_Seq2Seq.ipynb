{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Machine translation seq2seq model German -> English\n",
    "\n",
    "<img src=\"./assets/4.png\" width=\"500\"/>\n",
    "\n",
    "#### References\n",
    "- [Paper](https://arxiv.org/abs/1409.3215)\n",
    "- [Github](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)\n",
    "- [Youtube](https://www.youtube.com/watch?v=EoGUlvhRYpk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Use {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'morning']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_en(\"good morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['morgen', 'guten']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_de(\"guten morgen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get dataset from torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "english = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'), \n",
    "    fields = (german, english))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei']\n",
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "# DE (reverse)\n",
    "print(vars(train_data.examples[0])['src'])\n",
    "\n",
    "# En\n",
    "print(vars(train_data.examples[0])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'männer', 'mehrere']\n",
      "['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']\n"
     ]
    }
   ],
   "source": [
    "# DE (reverse)\n",
    "print(vars(train_data.examples[1])['src'])\n",
    "\n",
    "# En\n",
    "print(vars(train_data.examples[1])['trg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, min_freq = 2)\n",
    "english.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7854\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(german.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Preview dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader size: 227\n",
      "Valid dataloader size: 8\n",
      "Test dataloader size: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataloader size:\", len(train_iterator))\n",
    "print(\"Valid dataloader size:\", len(valid_iterator))\n",
    "print(\"Test dataloader size:\", len(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source[0] tensor size: torch.Size([27, 128])\n",
      "Target[0] tensor size: torch.Size([25, 128])\n",
      "\n",
      "Source[1] tensor size: torch.Size([25, 128])\n",
      "Target[1] tensor size: torch.Size([27, 128])\n",
      "\n",
      "Source[2] tensor size: torch.Size([38, 128])\n",
      "Target[2] tensor size: torch.Size([36, 128])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_iterator):\n",
    "    X = data.src\n",
    "    y = data.trg\n",
    "\n",
    "    # (Input_dim, batch_size)\n",
    "    print(f\"Source[{i}] tensor size: {X.size()}\")\n",
    "\n",
    "    # (Output_dim, batch_size)\n",
    "    print(f\"Target[{i}] tensor size: {y.size()}\",end=\"\\n\\n\")\n",
    "\n",
    "    if i == 2: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Encoder\n",
    "\n",
    "<img src=\"./assets/2.png\" width=\"400\"/>\n",
    "\n",
    "- Encode 1 sentence at a time\n",
    "\n",
    "#### Architecture\n",
    "- 1 Embedding: Map a word in dictionary size N -> vector M dimension\n",
    "- 2 layer LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Seq2Seq import Encoder\n",
    "\n",
    "\n",
    "ENC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(\n",
    "    source_vocab_size=len(german.vocab),\n",
    "    embedding_size=ENC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=ENC_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decoder\n",
    "\n",
    "<img src=\"./assets/3.png\" width=\"400\"/>\n",
    "\n",
    "- Predict 1 word at a time\n",
    "#### Architecture\n",
    "- 1 Embedding: Map a word in dictionary size N -> vector M dimension\n",
    "- 2 layer LSTM\n",
    "- 1 fully connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Seq2Seq import Decoder\n",
    "\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "dec = Decoder(\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    embedding_size=DEC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=DEC_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Seq2Seq\n",
    "\n",
    "<img src=\"./assets/1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Seq2Seq import Seq2Seq\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder=enc,\n",
    "    decoder=dec,\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC_EMB_DIM = 300\n",
    "ENC_DROPOUT = 0.5\n",
    "\n",
    "DEC_EMB_DIM = 300\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "HID_DIM = 1024\n",
    "N_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    source_vocab_size=len(german.vocab),\n",
    "    embedding_size=ENC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=ENC_DROPOUT).to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    embedding_size=DEC_EMB_DIM,\n",
    "    hidden_size=HID_DIM,\n",
    "    num_layers=N_LAYERS,\n",
    "    dropout_rate=DEC_DROPOUT).to(device)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder=encoder_net,\n",
    "    decoder=decoder_net,\n",
    "    target_vocab_size=len(english.vocab),\n",
    "    device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss_fn\n",
    "import torch.nn as nn\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"exp/Seq2Seq/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "\n",
    "load_model = False\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"exp/Seq2Seq/trained_model.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = False\n",
    "LOG_FILE = \"exp/Seq2Seq/train.log\"\n",
    "\n",
    "if train_mode == True:\n",
    "    # a boat with several men on it is being pulled ashore by a large team of horses.\n",
    "    sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_iterator):\n",
    "            # Get input and targets and get to cuda\n",
    "            source = batch.src.to(device)\n",
    "            target = batch.trg.to(device)\n",
    "\n",
    "            # Forward prop\n",
    "            output = model(source, target)\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "            # within a healthy range\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        save_checkpoint(checkpoint, \"exp/Seq2Seq/trained_model.pth.tar\")\n",
    "\n",
    "\n",
    "        # Plot to tensorboard every epoch\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        translated_sentence = translate_sentence(\n",
    "            model, sentence, german, english, device, max_length=50\n",
    "        )\n",
    "        with open(LOG_FILE, \"a+\") as file:\n",
    "            file.write(f\"[Epoch {epoch} / {num_epochs}]: loss: {loss.item()}\\n\")\n",
    "            file.write(f\"Translated example sentence: {' '.join(translated_sentence)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load(\"exp/Seq2Seq/trained_model.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence: . freien im tag schönen einen genießen sohn kleiner ihr und mutter eine\n",
      "groundtruth: a mother and her young song enjoying a beautiful day outside .\n",
      "translated: a mother and her mother are admiring a go in a snowy winter .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = test_data[10].src\n",
    "groundtruth = test_data[10].trg\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, german, english, device, max_length=50\n",
    ")\n",
    "\n",
    "print(f'''\n",
    "sentence: {' '.join(sentence)}\n",
    "groundtruth: {' '.join(groundtruth)}\n",
    "translated: {' '.join(translated_sentence[:-1])}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence: . feld dem auf trompete spiel einem bei spielt teenagerin eine\n",
      "groundtruth: a teenager plays her trumpet on the field at a game .\n",
      "translated: a playing playing hockey on a field on a court .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = test_data[21].src\n",
    "groundtruth = test_data[21].trg\n",
    "translated_sentence = translate_sentence(\n",
    "    model, sentence, german, english, device, max_length=50\n",
    ")\n",
    "\n",
    "print(f'''\n",
    "sentence: {' '.join(sentence)}\n",
    "groundtruth: {' '.join(groundtruth)}\n",
    "translated: {' '.join(translated_sentence[:-1])}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 15.52\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
